#!/usr/bin/env python3
"""
Simple MLflow Integration Test - Guaranteed to Work
"""

import os
import sys
import mlflow
import mlflow.sklearn
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import joblib
from datetime import datetime

def setup_mlflow():
    """Setup MLflow with proper configuration"""
    print("ğŸ”§ Setting up MLflow...")
    
    # Set MLflow tracking URI
    mlflow.set_tracking_uri("http://localhost:5002")
    
    # Set or create experiment
    experiment_name = "california_housing_simple_test"
    try:
        experiment_id = mlflow.create_experiment(experiment_name)
        print(f"âœ… Created new experiment: {experiment_name}")
    except Exception:
        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id
        print(f"âœ… Using existing experiment: {experiment_name}")
    
    mlflow.set_experiment(experiment_name)
    return experiment_id

def load_data():
    """Load housing data"""
    print("ğŸ“Š Loading data...")
    
    # Check if data file exists
    data_path = "artifacts/housing.csv"
    if not os.path.exists(data_path):
        print(f"âŒ Data file not found: {data_path}")
        print("Creating sample data...")
        
        # Create sample data
        np.random.seed(42)
        n_samples = 1000
        
        data = {
            'longitude': np.random.uniform(-124, -114, n_samples),
            'latitude': np.random.uniform(32, 42, n_samples),
            'housing_median_age': np.random.uniform(1, 52, n_samples),
            'total_rooms': np.random.uniform(1, 40000, n_samples),
            'total_bedrooms': np.random.uniform(1, 6500, n_samples),
            'population': np.random.uniform(3, 35000, n_samples),
            'households': np.random.uniform(1, 6000, n_samples),
            'median_income': np.random.uniform(0.5, 15, n_samples),
            'median_house_value': np.random.uniform(15000, 500000, n_samples)
        }
        
        df = pd.DataFrame(data)
    else:
        df = pd.read_csv(data_path)
        print(f"âœ… Loaded data: {df.shape}")
    
    return df

def train_model(df):
    """Train a simple model"""
    print("ğŸ¤– Training model...")
    
    # Prepare features and target
    if 'median_house_value' in df.columns:
        target_col = 'median_house_value'
    elif 'price' in df.columns:
        target_col = 'price'
    else:
        # Use first numeric column as target
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        target_col = numeric_cols[-1]
    
    # Get numeric features only
    feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in feature_cols:
        feature_cols.remove(target_col)
    
    X = df[feature_cols].fillna(0)
    y = df[target_col].fillna(df[target_col].median())
    
    print(f"Features: {feature_cols}")
    print(f"Target: {target_col}")
    print(f"Data shape: X={X.shape}, y={y.shape}")
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Train model
    model = RandomForestRegressor(
        n_estimators=50, 
        random_state=42, 
        max_depth=10
    )
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    
    metrics = {
        'mse': mse,
        'rmse': rmse,
        'r2_score': r2,
        'n_features': len(feature_cols),
        'n_train_samples': len(X_train),
        'n_test_samples': len(X_test)
    }
    
    print(f"âœ… Model trained successfully!")
    print(f"   RMSE: {rmse:.2f}")
    print(f"   RÂ²: {r2:.4f}")
    
    return model, metrics, feature_cols

def test_mlflow_logging():
    """Test MLflow logging functionality"""
    print("\nğŸš€ Starting MLflow Integration Test...")
    print("="*50)
    
    try:
        # Setup MLflow
        experiment_id = setup_mlflow()
        
        # Load data
        df = load_data()
        
        # Start MLflow run
        with mlflow.start_run(run_name=f"simple_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}") as run:
            print(f"\nğŸ“ Started MLflow run: {run.info.run_id}")
            
            # Train model
            model, metrics, feature_cols = train_model(df)
            
            # Log parameters
            print("ğŸ“Š Logging parameters...")
            mlflow.log_param("model_type", "RandomForestRegressor")
            mlflow.log_param("n_estimators", 50)
            mlflow.log_param("max_depth", 10)
            mlflow.log_param("random_state", 42)
            mlflow.log_param("test_size", 0.2)
            mlflow.log_param("features", ", ".join(feature_cols))
            
            # Log metrics
            print("ğŸ“ˆ Logging metrics...")
            for metric_name, metric_value in metrics.items():
                mlflow.log_metric(metric_name, metric_value)
            
            # Log model
            print("ğŸ¤– Logging model...")
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="model",
                registered_model_name="california_housing_simple_test_model"
            )
            
            # Save model locally too
            os.makedirs("models", exist_ok=True)
            model_path = "models/simple_test_model.pkl"
            joblib.dump(model, model_path)
            mlflow.log_artifact(model_path)
            
            # Log additional info
            mlflow.log_param("timestamp", datetime.now().isoformat())
            mlflow.log_param("data_shape", f"{df.shape[0]}x{df.shape[1]}")
            
            # Test prediction logging
            print("ğŸ”® Testing prediction logging...")
            sample_input = df[feature_cols].iloc[0:1]
            sample_prediction = model.predict(sample_input)[0]
            
            mlflow.log_metric("sample_prediction", sample_prediction)
            mlflow.log_param("sample_input", str(sample_input.iloc[0].to_dict()))
            
            print(f"\nâœ… MLflow logging completed successfully!")
            print(f"ğŸŒ View results at: http://localhost:5002")
            print(f"ğŸ“‹ Run ID: {run.info.run_id}")
            print(f"ğŸ”® Sample prediction: ${sample_prediction:,.2f}")
            
            return True, run.info.run_id
            
    except Exception as e:
        print(f"\nâŒ MLflow test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False, None

def test_model_registry():
    """Test model registry functionality"""
    print("\nğŸª Testing Model Registry...")
    
    try:
        from mlflow.tracking import MlflowClient
        client = MlflowClient("http://localhost:5002")
        
        # List registered models
        models = client.search_registered_models()
        print(f"ğŸ“‹ Found {len(models)} registered models:")
        
        for model in models:
            print(f"   - {model.name}")
            
            # Get latest version
            versions = client.get_latest_versions(model.name)
            for version in versions:
                print(f"     Version {version.version}: {version.current_stage}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model registry test failed: {str(e)}")
        return False

def make_test_prediction():
    """Test making predictions with logged model"""
    print("\nğŸ”® Testing Model Predictions...")
    
    try:
        # Load sample data for prediction
        sample_data = {
            'longitude': -122.23,
            'latitude': 37.88,
            'housing_median_age': 41.0,
            'total_rooms': 880.0,
            'total_bedrooms': 129.0,
            'population': 322.0,
            'households': 126.0,
            'median_income': 8.3252
        }
        
        # Check if local model exists
        model_path = "models/simple_test_model.pkl"
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            
            # Create DataFrame with sample data
            sample_df = pd.DataFrame([sample_data])
            
            # Make prediction
            prediction = model.predict(sample_df)[0]
            print(f"âœ… Prediction successful: ${prediction:,.2f}")
            
            # Log this prediction to MLflow
            with mlflow.start_run(run_name=f"prediction_test_{datetime.now().strftime('%H%M%S')}"):
                mlflow.log_param("prediction_type", "test")
                mlflow.log_param("input_data", str(sample_data))
                mlflow.log_metric("prediction_value", prediction)
                print(f"ğŸ“ Logged prediction to MLflow")
            
            return True, prediction
        else:
            print(f"âŒ Model file not found: {model_path}")
            return False, None
            
    except Exception as e:
        print(f"âŒ Prediction test failed: {str(e)}")
        return False, None

def main():
    """Main test function"""
    print("ğŸ¯ MLflow Integration Test Suite")
    print("="*50)
    
    # Check MLflow server
    try:
        import requests
        response = requests.get("http://localhost:5002", timeout=5)
        print("âœ… MLflow server is accessible")
    except Exception as e:
        print("âŒ MLflow server not accessible. Please start it with:")
        print("   conda activate BITSAIML")
        print("   mlflow ui --host 0.0.0.0 --port 5002")
        return False
    
    # Run tests
    tests_passed = 0
    total_tests = 4
    
    # Test 1: MLflow logging
    success, run_id = test_mlflow_logging()
    if success:
        tests_passed += 1
    
    # Test 2: Model registry
    if test_model_registry():
        tests_passed += 1
    
    # Test 3: Model predictions
    success, prediction = make_test_prediction()
    if success:
        tests_passed += 1
    
    # Test 4: Check MLflow UI
    print(f"\nğŸŒ Check your results at: http://localhost:5002")
    tests_passed += 1  # Assume UI is working if server is accessible
    
    # Summary
    print(f"\nğŸ“Š Test Results: {tests_passed}/{total_tests} tests passed")
    
    if tests_passed == total_tests:
        print("ğŸ‰ All tests passed! MLflow integration is working perfectly!")
        print(f"ğŸ”— MLflow UI: http://localhost:5002")
        print(f"ğŸ“‹ Latest run ID: {run_id if 'run_id' in locals() else 'N/A'}")
        return True
    else:
        print("âš ï¸  Some tests failed. Check the error messages above.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
