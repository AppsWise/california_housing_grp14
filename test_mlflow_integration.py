#!/usr/bin/env python3
"""
MLflow Integration Test Script
==============================

Test script to verify MLflow model registry and tracking integration
with the California Housing API.

Author: Group 14
Date: August 2025
"""

import os
import sys
import requests
import json
import time
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.utils.mlflow_tracking import get_model_registry, get_experiment_tracker, initialize_mlflow_tracking


def test_mlflow_initialization():
    """Test MLflow component initialization"""
    print("üîß Testing MLflow Initialization...")
    
    try:
        success = initialize_mlflow_tracking()
        if success:
            print("‚úÖ MLflow tracking components initialized successfully")
            return True
        else:
            print("‚ùå MLflow initialization failed")
            return False
    except Exception as e:
        print(f"‚ùå Error initializing MLflow: {e}")
        return False


def test_model_registry():
    """Test model registry functionality"""
    print("\nüìã Testing Model Registry...")
    
    try:
        registry = get_model_registry()
        
        # List registered models
        models = registry.list_registered_models()
        print(f"‚úÖ Found {len(models)} registered models")
        
        for model in models:
            print(f"  - {model['name']}")
            
        # Test model info retrieval
        if models:
            model_name = models[0]["name"]
            model_info = registry.get_model_info(model_name)
            print(f"‚úÖ Retrieved info for model: {model_name}")
            print(f"  Latest versions: {model_info.get('latest_versions', {})}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing model registry: {e}")
        return False


def test_model_loading():
    """Test model loading from registry"""
    print("\nüèóÔ∏è Testing Model Loading...")
    
    try:
        registry = get_model_registry()
        
        # Try to load the california housing model
        model_name = "california_housing_best_model"
        try:
            model, metadata = registry.load_model_from_registry(model_name, "Production")
            print(f"‚úÖ Model loaded from registry: {model_name}")
            print(f"  Version: {metadata['version']}")
            print(f"  Stage: {metadata['stage']}")
            print(f"  Model URI: {metadata['model_uri']}")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load from registry: {e}")
            print("  This is expected if no model is registered yet")
            return True  # Not a failure if no model exists
            
    except Exception as e:
        print(f"‚ùå Error testing model loading: {e}")
        return False


def test_experiment_tracking():
    """Test experiment tracking functionality"""
    print("\nüìä Testing Experiment Tracking...")
    
    try:
        tracker = get_experiment_tracker("test_experiment")
        
        # Test logging a dummy prediction batch
        dummy_predictions = [
            {
                "input_data": {"longitude": -122.23, "latitude": 37.88, "housing_median_age": 41.0},
                "prediction": 350000.0,
                "processing_time_ms": 15.5,
                "timestamp": "2025-08-06T10:00:00Z",
                "model_metadata": {"name": "test_model", "version": "1.0"}
            }
        ]
        
        model_metadata = {"name": "test_model", "version": "1.0", "stage": "Testing"}
        tracker.log_prediction_batch(dummy_predictions, model_metadata)
        
        print("‚úÖ Successfully logged test prediction batch")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing experiment tracking: {e}")
        return False


def test_api_integration():
    """Test API endpoints with MLflow integration"""
    print("\nüåê Testing API Integration...")
    
    # Assume API is running on default port
    base_url = "http://localhost:5001"
    
    try:
        # Test health endpoint
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code == 200:
            health_data = response.json()
            print("‚úÖ Health endpoint accessible")
            print(f"  Model loaded: {health_data.get('model_loaded')}")
            print(f"  Model version: {health_data.get('model_version')}")
        else:
            print(f"‚ö†Ô∏è Health endpoint returned status: {response.status_code}")
        
        # Test model info endpoint
        try:
            response = requests.get(f"{base_url}/api/model/info", timeout=5)
            if response.status_code == 200:
                model_info = response.json()
                print("‚úÖ Model info endpoint accessible")
                print(f"  MLflow enabled: {model_info.get('model_info', {}).get('mlflow_enabled')}")
            else:
                print(f"‚ö†Ô∏è Model info endpoint returned status: {response.status_code}")
        except requests.exceptions.RequestException:
            print("‚ö†Ô∏è Model info endpoint not accessible (API may not be running)")
        
        # Test MLflow models endpoint
        try:
            response = requests.get(f"{base_url}/api/mlflow/models", timeout=5)
            if response.status_code == 200:
                models_data = response.json()
                print("‚úÖ MLflow models endpoint accessible")
                print(f"  Registered models count: {models_data.get('count', 0)}")
            else:
                print(f"‚ö†Ô∏è MLflow models endpoint returned status: {response.status_code}")
        except requests.exceptions.RequestException:
            print("‚ö†Ô∏è MLflow models endpoint not accessible (API may not be running)")
        
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è API not accessible (likely not running): {e}")
        print("  Start the API with: python src/api/app.py")
        return True  # Not a failure if API isn't running


def test_prediction_with_mlflow():
    """Test making a prediction through the API with MLflow tracking"""
    print("\nüéØ Testing Prediction with MLflow Tracking...")
    
    base_url = "http://localhost:5001"
    
    try:
        # Test prediction endpoint
        test_data = {
            "longitude": -122.23,
            "latitude": 37.88,
            "housing_median_age": 41.0,
            "total_rooms": 880.0,
            "total_bedrooms": 129.0,
            "population": 322.0,
            "households": 126.0,
            "median_income": 8.3252,
            "ocean_proximity": "NEAR BAY"
        }
        
        response = requests.post(
            f"{base_url}/api/predict",
            json=test_data,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        
        if response.status_code == 200:
            prediction_data = response.json()
            print("‚úÖ Prediction successful")
            print(f"  Prediction: ${prediction_data.get('prediction', 0):,.2f}")
            print(f"  Model version: {prediction_data.get('model_version')}")
            print(f"  Processing time: {prediction_data.get('processing_time_ms')}ms")
            return True
        else:
            print(f"‚ö†Ô∏è Prediction failed with status: {response.status_code}")
            print(f"  Response: {response.text}")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è Cannot test prediction (API not accessible): {e}")
        return True  # Not a failure if API isn't running


def main():
    """Run all MLflow integration tests"""
    print("=" * 70)
    print("MLFLOW INTEGRATION TEST SUITE")
    print("=" * 70)
    
    # Set environment variables for testing
    os.environ["MLFLOW_TRACKING_URI"] = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
    
    tests = [
        ("MLflow Initialization", test_mlflow_initialization),
        ("Model Registry", test_model_registry),
        ("Model Loading", test_model_loading),
        ("Experiment Tracking", test_experiment_tracking),
        ("API Integration", test_api_integration),
        ("Prediction with MLflow", test_prediction_with_mlflow),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'-' * 50}")
        results[test_name] = test_func()
    
    # Summary
    print("\n" + "=" * 70)
    print("TEST RESULTS SUMMARY")
    print("=" * 70)
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{test_name:<30} {status}")
        if result:
            passed += 1
    
    print(f"\nPassed: {passed}/{total}")
    
    if passed == total:
        print("\nüéâ ALL TESTS PASSED!")
        print("MLflow integration is working correctly.")
    else:
        print(f"\n‚ö†Ô∏è {total - passed} TESTS FAILED")
        print("Check the error messages above for issues.")
    
    print("\n" + "=" * 70)
    print("NEXT STEPS:")
    print("1. Start MLflow server: mlflow ui --port 5000")
    print("2. Train and register a model: python src/models/train.py")
    print("3. Start the API: python src/api/app.py")
    print("4. View MLflow UI: http://localhost:5000")
    print("5. Test API endpoints: http://localhost:5001")
    print("=" * 70)


if __name__ == "__main__":
    main()
